{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55dd5e56-c96f-4c5d-a959-60b1aa727201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8832, 26) Test shape: (2208, 26)\n",
      "Train fraud rate: 0.07676630434782608 Test fraud rate: 0.1408514492753623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imbalance tools\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---- Load your processed dataset ----\n",
    "DATA_PATH = \"../data/processed/cleaned_transactions.csv\"\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "TARGET_COL = \"is_fraud\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[TIMESTAMP_COL] = pd.to_datetime(df[TIMESTAMP_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TIMESTAMP_COL]).sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "\n",
    "# ---- Feature groups ----\n",
    "numeric_features = (\n",
    "    df.select_dtypes(include=[\"number\"])\n",
    "      .columns\n",
    "      .drop([TARGET_COL], errors=\"ignore\")\n",
    "      .tolist()\n",
    ")\n",
    "categorical_features = (\n",
    "    df.select_dtypes(include=[\"object\", \"category\", \"bool\"])\n",
    "      .columns\n",
    "      .drop([TARGET_COL, TIMESTAMP_COL], errors=\"ignore\")\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "# ---- Time split (same approach as Day 1) ----\n",
    "split_index = int(len(df) * 0.8)\n",
    "X_train_raw, X_test_raw = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "print(\"Train shape:\", X_train_raw.shape, \"Test shape:\", X_test_raw.shape)\n",
    "print(\"Train fraud rate:\", y_train.mean(), \"Test fraud rate:\", y_test.mean())\n",
    "\n",
    "# ---- Preprocessing ----\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "\n",
    "# ---- Experiment logger ----\n",
    "def evaluate_probs(y_true, y_proba, threshold=0.5):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    return {\n",
    "        \"threshold\": threshold,\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "experiment_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb968fe-5b01-4d49-beb2-25831e6b241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imblearn version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "print(\"imblearn version:\", imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd74f1f6-7901-4067-836b-3626565b40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\n",
    "\n",
    "def eval_at_threshold(y_true, y_proba, threshold=0.5):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    return {\n",
    "        \"threshold\": threshold,\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "    }\n",
    "\n",
    "experiment_log = []\n",
    "\n",
    "def log_result(model_name, imbalance_method, y_true, y_proba, threshold=0.5, notes=\"\"):\n",
    "    row = {\n",
    "        \"model\": model_name,\n",
    "        \"imbalance_method\": imbalance_method,\n",
    "        **eval_at_threshold(y_true, y_proba, threshold),\n",
    "        \"notes\": notes\n",
    "    }\n",
    "\n",
    "    # remove any existing row with same model + method + threshold\n",
    "    global experiment_log\n",
    "    experiment_log = [\n",
    "        r for r in experiment_log\n",
    "        if not (r[\"model\"] == model_name and r[\"imbalance_method\"] == imbalance_method and r[\"threshold\"] == threshold)\n",
    "    ]\n",
    "\n",
    "    experiment_log.append(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3b379-1635-4315-9ff2-259927440e51",
   "metadata": {},
   "source": [
    "## Random Forest + Random UnderSampling (Imbalance Handling)\n",
    "\n",
    "### Why are we doing this?\n",
    "Fraud datasets are imbalanced (few fraud cases, many legitimate cases). Many models become biased toward predicting “legit” because that’s the majority class.\n",
    "\n",
    "**RandomUnderSampler** reduces the number of legitimate transactions in the training set so the model sees a more balanced dataset during learning.  \n",
    "This often improves **recall** (catching more fraud), but it can sometimes reduce **precision** (more false alarms).\n",
    "\n",
    "### What this experiment does\n",
    "1. Applies the same preprocessing pipeline (scaling numeric + encoding categorical).\n",
    "2. Undersamples the majority class (legit) **only on the training data**.\n",
    "3. Trains a Random Forest model.\n",
    "4. Predicts fraud probabilities on the test set.\n",
    "5. Evaluates precision, recall, F1, and ROC-AUC at a chosen threshold (0.5).\n",
    "6. Logs the results into our experiment tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35bdd556-bf12-4f42-9e1d-9b4df61dab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>Baseline RF + undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    imbalance_method  threshold  precision    recall        f1  \\\n",
       "0  RandomForest  RandomUnderSampler        0.5   0.903427  0.932476  0.917722   \n",
       "\n",
       "    roc_auc                        notes  \n",
       "0  0.978038  Baseline RF + undersampling  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Random Forest + UnderSampling (Imbalance Handling)\n",
    "# =========================\n",
    "\n",
    "# 1) Import the model and imbalance tool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# 2) Build an imbalanced-learn pipeline\n",
    "#    Why ImbPipeline?\n",
    "#    - It allows sampling steps (like RandomUnderSampler) inside a pipeline\n",
    "#    - It ensures the sampler runs ONLY during training (fit), not during predict\n",
    "rf_under = ImbPipeline(steps=[\n",
    "    (\"preprocess\", preprocess),  # (a) apply preprocessing: impute + scale + one-hot encode\n",
    "    (\"under\", RandomUnderSampler(random_state=42)),  # (b) undersample majority class in TRAIN only\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,      # number of trees (more trees = more stable, but slower)\n",
    "        random_state=42,       # for reproducibility\n",
    "        n_jobs=-1              # use all CPU cores\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3) Train the pipeline on the training split\n",
    "rf_under.fit(X_train_raw, y_train)\n",
    "\n",
    "# 4) Predict probabilities on the test split\n",
    "#    We take [:, 1] because column 1 is the probability of class 1 (fraud)\n",
    "y_proba = rf_under.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "# 5) Log results (evaluated at threshold=0.5)\n",
    "#    This stores metrics in your experiment_log list so we can compare many runs later\n",
    "log_result(\n",
    "    model_name=\"RandomForest\",\n",
    "    imbalance_method=\"RandomUnderSampler\",\n",
    "    y_true=y_test,\n",
    "    y_proba=y_proba,\n",
    "    threshold=0.5,\n",
    "    notes=\"Baseline RF + undersampling\"\n",
    ")\n",
    "\n",
    "# 6) Display experiment results sorted by best F1 score\n",
    "pd.DataFrame(experiment_log).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c386a0-21a4-4bcc-8331-c63e7a33f3e3",
   "metadata": {},
   "source": [
    "## Random Forest + SMOTE (Oversampling the Minority Class)\n",
    "\n",
    "### Why SMOTE?\n",
    "Undersampling throws away many legitimate transactions, which can remove useful patterns.\n",
    "**SMOTE** (Synthetic Minority Oversampling Technique) instead *adds* synthetic fraud samples to the training set, making the classes more balanced **without deleting majority-class data**.\n",
    "\n",
    "### What this experiment does\n",
    "1. Preprocess the data (impute + scale + one-hot encode).\n",
    "2. Apply SMOTE **on the training data only** to generate additional fraud-like samples.\n",
    "3. Train a Random Forest model on the SMOTE-balanced training data.\n",
    "4. Predict fraud probabilities on the untouched test set.\n",
    "5. Evaluate and log performance (precision, recall, F1, ROC-AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde5b7ae-2719-417e-b882-40951e1bb650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>RF + SMOTE oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>Baseline RF + undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    imbalance_method  threshold  precision    recall        f1  \\\n",
       "1  RandomForest               SMOTE        0.5   1.000000  0.916399  0.956376   \n",
       "0  RandomForest  RandomUnderSampler        0.5   0.903427  0.932476  0.917722   \n",
       "\n",
       "    roc_auc                        notes  \n",
       "1  0.971303      RF + SMOTE oversampling  \n",
       "0  0.978038  Baseline RF + undersampling  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Random Forest + SMOTE (Imbalance Handling)\n",
    "# =========================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# NOTE:\n",
    "# SMOTE creates synthetic minority samples by looking at nearest neighbors.\n",
    "# It works best on numeric feature spaces. Since we one-hot encode categoricals,\n",
    "# SMOTE can still run, but it's not always ideal for one-hot encoded data.\n",
    "# For today (Day 3), it's still a valid experiment. Later, we can consider SMOTENC.\n",
    "\n",
    "rf_smote = ImbPipeline(steps=[\n",
    "    (\"preprocess\", preprocess),                 # (a) preprocessing\n",
    "    (\"smote\", SMOTE(random_state=42)),          # (b) oversample fraud class in TRAIN only\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "rf_smote.fit(X_train_raw, y_train)\n",
    "\n",
    "# Predict probabilities on TEST\n",
    "y_proba = rf_smote.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name=\"RandomForest\",\n",
    "    imbalance_method=\"SMOTE\",\n",
    "    y_true=y_test,\n",
    "    y_proba=y_proba,\n",
    "    threshold=0.5,\n",
    "    notes=\"RF + SMOTE oversampling\"\n",
    ")\n",
    "\n",
    "# View results\n",
    "pd.DataFrame(experiment_log).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9712845-1116-40b6-b238-be28f5360965",
   "metadata": {},
   "source": [
    "## Random Forest + Class Weights (No Sampling)\n",
    "\n",
    "### Why this approach?\n",
    "Instead of changing the dataset size (undersampling) or generating synthetic samples (SMOTE),\n",
    "we tell the model that fraud errors are more costly by using **class_weight**.\n",
    "\n",
    "This often improves recall while keeping the dataset intact.\n",
    "\n",
    "### What this experiment does\n",
    "1. Preprocess data (impute + scale + one-hot encode)\n",
    "2. Train a Random Forest with class weighting\n",
    "3. Predict probabilities on the test set\n",
    "4. Evaluate precision/recall/F1/ROC-AUC and log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87742d3c-8143-4fdf-8504-e90ad1654263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>RF + SMOTE oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>class_weight=balanced_subsample</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.974102</td>\n",
       "      <td>RF without sampling; uses class weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>Baseline RF + undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                 imbalance_method  threshold  precision  \\\n",
       "1  RandomForest                            SMOTE        0.5   1.000000   \n",
       "2  RandomForest  class_weight=balanced_subsample        0.5   1.000000   \n",
       "0  RandomForest               RandomUnderSampler        0.5   0.903427   \n",
       "\n",
       "     recall        f1   roc_auc                                    notes  \n",
       "1  0.916399  0.956376  0.971303                  RF + SMOTE oversampling  \n",
       "2  0.916399  0.956376  0.974102  RF without sampling; uses class weights  \n",
       "0  0.932476  0.917722  0.978038              Baseline RF + undersampling  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Random Forest + Class Weights (No Sampling)\n",
    "# =========================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rf_weighted = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\"  # balances classes per tree sample\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "rf_weighted.fit(X_train_raw, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = rf_weighted.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name=\"RandomForest\",\n",
    "    imbalance_method=\"class_weight=balanced_subsample\",\n",
    "    y_true=y_test,\n",
    "    y_proba=y_proba,\n",
    "    threshold=0.5,\n",
    "    notes=\"RF without sampling; uses class weights\"\n",
    ")\n",
    "\n",
    "# View log (latest runs only)\n",
    "pd.DataFrame(experiment_log).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f94783b-f0a9-409e-9d13-77ec29b6022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xgboost is installed\n",
      "❌ lightgbm not installed -> No module named 'lightgbm'\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "for pkg in [\"xgboost\", \"lightgbm\"]:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "        print(f\"✅ {pkg} is installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {pkg} not installed -> {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eae38-2696-46eb-9ddd-4ca724fd28f0",
   "metadata": {},
   "source": [
    "## XGBoost (Advanced Model) + Imbalance Handling\n",
    "\n",
    "### Why XGBoost?\n",
    "XGBoost is a strong gradient-boosting model that often outperforms bagging models (like Random Forest)\n",
    "on structured/tabular datasets.\n",
    "\n",
    "### How we handle imbalance in XGBoost\n",
    "Instead of SMOTE/undersampling, XGBoost can directly weight the minority class using:\n",
    "\n",
    "**scale_pos_weight = (#negative / #positive)**\n",
    "\n",
    "This tells the model that fraud errors are more costly and often improves recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989e816b-e210-4ddc-ab21-a31f02a07bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 12.026548672566372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>RF + SMOTE oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>class_weight=balanced_subsample</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.974102</td>\n",
       "      <td>RF without sampling; uses class weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>Baseline RF + undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.909380</td>\n",
       "      <td>0.975314</td>\n",
       "      <td>XGB with class weighting (no sampling)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                 imbalance_method  threshold  precision  \\\n",
       "1  RandomForest                            SMOTE        0.5   1.000000   \n",
       "2  RandomForest  class_weight=balanced_subsample        0.5   1.000000   \n",
       "0  RandomForest               RandomUnderSampler        0.5   0.903427   \n",
       "3       XGBoost           scale_pos_weight=12.03        0.5   0.899371   \n",
       "\n",
       "     recall        f1   roc_auc                                    notes  \n",
       "1  0.916399  0.956376  0.971303                  RF + SMOTE oversampling  \n",
       "2  0.916399  0.956376  0.974102  RF without sampling; uses class weights  \n",
       "0  0.932476  0.917722  0.978038              Baseline RF + undersampling  \n",
       "3  0.919614  0.909380  0.975314   XGB with class weighting (no sampling)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1) Compute scale_pos_weight from training set\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# 2) XGBoost pipeline (uses same preprocessing)\n",
    "xgb_weighted = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3) Train\n",
    "xgb_weighted.fit(X_train_raw, y_train)\n",
    "\n",
    "# 4) Predict probabilities (fraud class)\n",
    "y_proba = xgb_weighted.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "# 5) Log results\n",
    "log_result(\n",
    "    model_name=\"XGBoost\",\n",
    "    imbalance_method=f\"scale_pos_weight={scale_pos_weight:.2f}\",\n",
    "    y_true=y_test,\n",
    "    y_proba=y_proba,\n",
    "    threshold=0.5,\n",
    "    notes=\"XGB with class weighting (no sampling)\"\n",
    ")\n",
    "\n",
    "pd.DataFrame(experiment_log).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba41dd1-b9d9-4917-8d0c-ac24a48962c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.7,\n",
       " 'precision': 0.9827586206896551,\n",
       " 'recall': 0.9163987138263665,\n",
       " 'f1': 0.9484193011647254,\n",
       " 'roc_auc': 0.9753138734878392}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_t07 = eval_at_threshold(y_test, y_proba, threshold=0.7)\n",
    "xgb_t07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fcdd3f9-f17a-4694-b994-03fd03677aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.948419</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.937705</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.909380</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.857567</td>\n",
       "      <td>0.929260</td>\n",
       "      <td>0.891975</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.850073</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.653422</td>\n",
       "      <td>0.951768</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.473016</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>0.633369</td>\n",
       "      <td>0.975314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        imbalance_method  threshold  precision    recall        f1  \\\n",
       "6  XGBoost  scale_pos_weight=12.03        0.7   0.982759  0.916399  0.948419   \n",
       "5  XGBoost  scale_pos_weight=12.03        0.6   0.937705  0.919614  0.928571   \n",
       "4  XGBoost  scale_pos_weight=12.03        0.5   0.899371  0.919614  0.909380   \n",
       "3  XGBoost  scale_pos_weight=12.03        0.4   0.857567  0.929260  0.891975   \n",
       "2  XGBoost  scale_pos_weight=12.03        0.3   0.776596  0.938907  0.850073   \n",
       "1  XGBoost  scale_pos_weight=12.03        0.2   0.653422  0.951768  0.774869   \n",
       "0  XGBoost  scale_pos_weight=12.03        0.1   0.473016  0.958199  0.633369   \n",
       "\n",
       "    roc_auc  \n",
       "6  0.975314  \n",
       "5  0.975314  \n",
       "4  0.975314  \n",
       "3  0.975314  \n",
       "2  0.975314  \n",
       "1  0.975314  \n",
       "0  0.975314  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.round(np.arange(0.1, 0.8, 0.1), 1)  # 0.1 to 0.7\n",
    "\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    m = eval_at_threshold(y_test, y_proba, threshold=float(t))\n",
    "    rows.append({\n",
    "        \"model\": \"XGBoost\",\n",
    "        \"imbalance_method\": f\"scale_pos_weight={scale_pos_weight:.2f}\",\n",
    "        \"threshold\": float(t),\n",
    "        \"precision\": m[\"precision\"],\n",
    "        \"recall\": m[\"recall\"],\n",
    "        \"f1\": m[\"f1\"],\n",
    "        \"roc_auc\": m[\"roc_auc\"],\n",
    "    })\n",
    "\n",
    "xgb_threshold_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "xgb_threshold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc28170-6c74-4b08-90c9-5d65a87de556",
   "metadata": {},
   "source": [
    "## LightGBM (Advanced Model) + Imbalance Handling\n",
    "\n",
    "### Why LightGBM?\n",
    "LightGBM is a fast gradient-boosting model (like XGBoost) that often performs very well on tabular data.\n",
    "It can handle imbalance using built-in weighting instead of resampling.\n",
    "\n",
    "### Imbalance strategy used\n",
    "We use **class_weight=\"balanced\"** so the model penalizes mistakes on fraud (minority) more heavily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90084463-3959-4961-a911-7c742e34b4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 678, number of negative: 8154\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2396\n",
      "[LightGBM] [Info] Number of data points in the train set: 8832, number of used features: 184\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>RF + SMOTE oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>class_weight=balanced_subsample</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.974102</td>\n",
       "      <td>RF without sampling; uses class weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>0.966474</td>\n",
       "      <td>LGBM with class weighting (no sampling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>Baseline RF + undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>scale_pos_weight=12.03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.909380</td>\n",
       "      <td>0.975314</td>\n",
       "      <td>XGB with class weighting (no sampling)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                 imbalance_method  threshold  precision  \\\n",
       "1  RandomForest                            SMOTE        0.5   1.000000   \n",
       "2  RandomForest  class_weight=balanced_subsample        0.5   1.000000   \n",
       "4      LightGBM            class_weight=balanced        0.5   0.972696   \n",
       "0  RandomForest               RandomUnderSampler        0.5   0.903427   \n",
       "3       XGBoost           scale_pos_weight=12.03        0.5   0.899371   \n",
       "\n",
       "     recall        f1   roc_auc                                    notes  \n",
       "1  0.916399  0.956376  0.971303                  RF + SMOTE oversampling  \n",
       "2  0.916399  0.956376  0.974102  RF without sampling; uses class weights  \n",
       "4  0.916399  0.943709  0.966474  LGBM with class weighting (no sampling)  \n",
       "0  0.932476  0.917722  0.978038              Baseline RF + undersampling  \n",
       "3  0.919614  0.909380  0.975314   XGB with class weighting (no sampling)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_weighted = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LGBMClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"   # imbalance handling\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "lgbm_weighted.fit(X_train_raw, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = lgbm_weighted.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "# Log\n",
    "log_result(\n",
    "    model_name=\"LightGBM\",\n",
    "    imbalance_method=\"class_weight=balanced\",\n",
    "    y_true=y_test,\n",
    "    y_proba=y_proba,\n",
    "    threshold=0.5,\n",
    "    notes=\"LGBM with class weighting (no sampling)\"\n",
    ")\n",
    "\n",
    "pd.DataFrame(experiment_log).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "559f23c0-f3d4-4107-9633-089be735fa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.951586</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.948419</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.939044</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.946844</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>class_weight=balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.966474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model       imbalance_method  threshold  precision    recall        f1  \\\n",
       "6  LightGBM  class_weight=balanced        0.7   0.989583  0.916399  0.951586   \n",
       "5  LightGBM  class_weight=balanced        0.6   0.982759  0.916399  0.948419   \n",
       "4  LightGBM  class_weight=balanced        0.5   0.972696  0.916399  0.943709   \n",
       "3  LightGBM  class_weight=balanced        0.4   0.969388  0.916399  0.942149   \n",
       "2  LightGBM  class_weight=balanced        0.3   0.962838  0.916399  0.939044   \n",
       "1  LightGBM  class_weight=balanced        0.2   0.946844  0.916399  0.931373   \n",
       "0  LightGBM  class_weight=balanced        0.1   0.922330  0.916399  0.919355   \n",
       "\n",
       "    roc_auc  \n",
       "6  0.966474  \n",
       "5  0.966474  \n",
       "4  0.966474  \n",
       "3  0.966474  \n",
       "2  0.966474  \n",
       "1  0.966474  \n",
       "0  0.966474  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.round(np.arange(0.1, 0.8, 0.1), 1)\n",
    "\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    m = eval_at_threshold(y_test, y_proba, threshold=float(t))  # y_proba from LightGBM\n",
    "    rows.append({\n",
    "        \"model\": \"LightGBM\",\n",
    "        \"imbalance_method\": \"class_weight=balanced\",\n",
    "        \"threshold\": float(t),\n",
    "        \"precision\": m[\"precision\"],\n",
    "        \"recall\": m[\"recall\"],\n",
    "        \"f1\": m[\"f1\"],\n",
    "        \"roc_auc\": m[\"roc_auc\"],\n",
    "    })\n",
    "\n",
    "lgbm_threshold_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "lgbm_threshold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e9e6e-ad7a-4f86-9c4b-e2c559b87d48",
   "metadata": {},
   "source": [
    "## Reflection (fraud prevalence over time & stability):\n",
    "Fraud prevalence increased from the training period (7.7%) to the test period (14.1%), showing the distribution of the target changes over time. \n",
    "When prevalence shifts, a fixed threshold can produce different precision/recall behaviour because the base rate of fraud affects how many alerts the model generates and how many are true positives. This can make model performance less stable in production, especially precision, because more (or fewer) cases fall above the decision threshold depending on the time window. \n",
    "\n",
    "As a result, models should be validated on time-based splits and monitored continuously, with periodic threshold recalibration. Using imbalance-aware approaches (class weights, SMOTE, tuned thresholds) helps maintain recall while controlling false positives under changing fraud rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21417019-0405-4ace-b0ee-cc613e564c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
